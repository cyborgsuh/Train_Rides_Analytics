{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction ID</th>\n",
       "      <th>Date of Purchase</th>\n",
       "      <th>Time of Purchase</th>\n",
       "      <th>Purchase Type</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Railcard</th>\n",
       "      <th>Ticket Class</th>\n",
       "      <th>Ticket Type</th>\n",
       "      <th>Price</th>\n",
       "      <th>Departure Station</th>\n",
       "      <th>Arrival Destination</th>\n",
       "      <th>Date of Journey</th>\n",
       "      <th>Departure Time</th>\n",
       "      <th>Arrival Time</th>\n",
       "      <th>Actual Arrival Time</th>\n",
       "      <th>Journey Status</th>\n",
       "      <th>Reason for Delay</th>\n",
       "      <th>Refund Request</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>da8a6ba8-b3dc-4677-b176</td>\n",
       "      <td>2023-12-08</td>\n",
       "      <td>12:41:11</td>\n",
       "      <td>Online</td>\n",
       "      <td>Contactless</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Advance</td>\n",
       "      <td>43</td>\n",
       "      <td>London Paddington</td>\n",
       "      <td>Liverpool Lime Street</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>13:30:00</td>\n",
       "      <td>13:30:00</td>\n",
       "      <td>On Time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b0cdd1b0-f214-4197-be53</td>\n",
       "      <td>2023-12-16</td>\n",
       "      <td>11:23:01</td>\n",
       "      <td>Station</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Advance</td>\n",
       "      <td>23</td>\n",
       "      <td>London Kings Cross</td>\n",
       "      <td>York</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>09:45:00</td>\n",
       "      <td>11:35:00</td>\n",
       "      <td>11:40:00</td>\n",
       "      <td>Delayed</td>\n",
       "      <td>Signal Failure</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f3ba7a96-f713-40d9-9629</td>\n",
       "      <td>2023-12-19</td>\n",
       "      <td>19:51:27</td>\n",
       "      <td>Online</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Advance</td>\n",
       "      <td>3</td>\n",
       "      <td>Liverpool Lime Street</td>\n",
       "      <td>Manchester Piccadilly</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>18:15:00</td>\n",
       "      <td>18:45:00</td>\n",
       "      <td>18:45:00</td>\n",
       "      <td>On Time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b2471f11-4fe7-4c87-8ab4</td>\n",
       "      <td>2023-12-20</td>\n",
       "      <td>23:00:36</td>\n",
       "      <td>Station</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Advance</td>\n",
       "      <td>13</td>\n",
       "      <td>London Paddington</td>\n",
       "      <td>Reading</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>21:30:00</td>\n",
       "      <td>22:30:00</td>\n",
       "      <td>22:30:00</td>\n",
       "      <td>On Time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2be00b45-0762-485e-a7a3</td>\n",
       "      <td>2023-12-27</td>\n",
       "      <td>18:22:56</td>\n",
       "      <td>Online</td>\n",
       "      <td>Contactless</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Advance</td>\n",
       "      <td>76</td>\n",
       "      <td>Liverpool Lime Street</td>\n",
       "      <td>London Euston</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>16:45:00</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>On Time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Transaction ID Date of Purchase Time of Purchase Purchase Type  \\\n",
       "0  da8a6ba8-b3dc-4677-b176       2023-12-08         12:41:11        Online   \n",
       "1  b0cdd1b0-f214-4197-be53       2023-12-16         11:23:01       Station   \n",
       "2  f3ba7a96-f713-40d9-9629       2023-12-19         19:51:27        Online   \n",
       "3  b2471f11-4fe7-4c87-8ab4       2023-12-20         23:00:36       Station   \n",
       "4  2be00b45-0762-485e-a7a3       2023-12-27         18:22:56        Online   \n",
       "\n",
       "  Payment Method Railcard Ticket Class Ticket Type  Price  \\\n",
       "0    Contactless    Adult     Standard     Advance     43   \n",
       "1    Credit Card    Adult     Standard     Advance     23   \n",
       "2    Credit Card      NaN     Standard     Advance      3   \n",
       "3    Credit Card      NaN     Standard     Advance     13   \n",
       "4    Contactless      NaN     Standard     Advance     76   \n",
       "\n",
       "       Departure Station    Arrival Destination Date of Journey  \\\n",
       "0      London Paddington  Liverpool Lime Street      2024-01-01   \n",
       "1     London Kings Cross                   York      2024-01-01   \n",
       "2  Liverpool Lime Street  Manchester Piccadilly      2024-01-02   \n",
       "3      London Paddington                Reading      2024-01-01   \n",
       "4  Liverpool Lime Street          London Euston      2024-01-01   \n",
       "\n",
       "  Departure Time Arrival Time Actual Arrival Time Journey Status  \\\n",
       "0       11:00:00     13:30:00            13:30:00        On Time   \n",
       "1       09:45:00     11:35:00            11:40:00        Delayed   \n",
       "2       18:15:00     18:45:00            18:45:00        On Time   \n",
       "3       21:30:00     22:30:00            22:30:00        On Time   \n",
       "4       16:45:00     19:00:00            19:00:00        On Time   \n",
       "\n",
       "  Reason for Delay Refund Request  \n",
       "0              NaN             No  \n",
       "1   Signal Failure             No  \n",
       "2              NaN             No  \n",
       "3              NaN             No  \n",
       "4              NaN             No  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=r\".\\railway.csv\"\n",
    "df=pd.read_csv(path,low_memory=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_Purchase Type (Input  [(None, 1)]                  0         []                            \n",
      " Layer)                                                                                           \n",
      "                                                                                                  \n",
      " input_Payment Method (Inpu  [(None, 1)]                  0         []                            \n",
      " tLayer)                                                                                          \n",
      "                                                                                                  \n",
      " input_Railcard (InputLayer  [(None, 1)]                  0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " input_Ticket Class (InputL  [(None, 1)]                  0         []                            \n",
      " ayer)                                                                                            \n",
      "                                                                                                  \n",
      " input_Ticket Type (InputLa  [(None, 1)]                  0         []                            \n",
      " yer)                                                                                             \n",
      "                                                                                                  \n",
      " input_Departure Station (I  [(None, 1)]                  0         []                            \n",
      " nputLayer)                                                                                       \n",
      "                                                                                                  \n",
      " input_Arrival Destination   [(None, 1)]                  0         []                            \n",
      " (InputLayer)                                                                                     \n",
      "                                                                                                  \n",
      " input_Journey Status (Inpu  [(None, 1)]                  0         []                            \n",
      " tLayer)                                                                                          \n",
      "                                                                                                  \n",
      " input_Reason for Delay (In  [(None, 1)]                  0         []                            \n",
      " putLayer)                                                                                        \n",
      "                                                                                                  \n",
      " input_Refund Request (Inpu  [(None, 1)]                  0         []                            \n",
      " tLayer)                                                                                          \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 1, 2)                 4         ['input_Purchase Type[0][0]'] \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, 1, 2)                 6         ['input_Payment Method[0][0]']\n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)     (None, 1, 2)                 8         ['input_Railcard[0][0]']      \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)     (None, 1, 2)                 4         ['input_Ticket Class[0][0]']  \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)     (None, 1, 2)                 6         ['input_Ticket Type[0][0]']   \n",
      "                                                                                                  \n",
      " embedding_5 (Embedding)     (None, 1, 2)                 24        ['input_Departure Station[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " embedding_6 (Embedding)     (None, 1, 3)                 96        ['input_Arrival Destination[0]\n",
      "                                                                    [0]']                         \n",
      "                                                                                                  \n",
      " embedding_7 (Embedding)     (None, 1, 2)                 6         ['input_Journey Status[0][0]']\n",
      "                                                                                                  \n",
      " embedding_8 (Embedding)     (None, 1, 2)                 18        ['input_Reason for Delay[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " embedding_9 (Embedding)     (None, 1, 2)                 4         ['input_Refund Request[0][0]']\n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 1, 21)                0         ['embedding[0][0]',           \n",
      "                                                                     'embedding_1[0][0]',         \n",
      "                                                                     'embedding_2[0][0]',         \n",
      "                                                                     'embedding_3[0][0]',         \n",
      "                                                                     'embedding_4[0][0]',         \n",
      "                                                                     'embedding_5[0][0]',         \n",
      "                                                                     'embedding_6[0][0]',         \n",
      "                                                                     'embedding_7[0][0]',         \n",
      "                                                                     'embedding_8[0][0]',         \n",
      "                                                                     'embedding_9[0][0]']         \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 21)                   0         ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 128)                  2816      ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 64)                   8256      ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 32)                   2080      ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 32)                   0         ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 1)                    33        ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13361 (52.19 KB)\n",
      "Trainable params: 13361 (52.19 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "WARNING:tensorflow:From c:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "277/277 [==============================] - 4s 4ms/step - loss: 722.7901 - mae: 15.8710 - val_loss: 275.7495 - val_mae: 8.4477\n",
      "Epoch 2/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 206.7054 - mae: 7.9572 - val_loss: 102.8315 - val_mae: 5.8047\n",
      "Epoch 3/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 104.0626 - mae: 5.4403 - val_loss: 47.0821 - val_mae: 3.5219\n",
      "Epoch 4/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 78.4894 - mae: 4.5468 - val_loss: 30.3469 - val_mae: 2.7993\n",
      "Epoch 5/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 70.1029 - mae: 4.2972 - val_loss: 26.3784 - val_mae: 2.5915\n",
      "Epoch 6/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 65.3871 - mae: 4.0100 - val_loss: 17.5325 - val_mae: 1.9174\n",
      "Epoch 7/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 56.4276 - mae: 3.8278 - val_loss: 18.5177 - val_mae: 2.3865\n",
      "Epoch 8/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 57.3798 - mae: 3.8043 - val_loss: 9.7512 - val_mae: 1.3716\n",
      "Epoch 9/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 57.2462 - mae: 3.7892 - val_loss: 9.8916 - val_mae: 1.3601\n",
      "Epoch 10/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 56.4784 - mae: 3.7689 - val_loss: 9.7789 - val_mae: 1.7427\n",
      "Epoch 11/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 55.2048 - mae: 3.7364 - val_loss: 11.5103 - val_mae: 2.0513\n",
      "Epoch 12/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 51.1480 - mae: 3.5903 - val_loss: 6.5134 - val_mae: 1.0411\n",
      "Epoch 13/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 51.9377 - mae: 3.5818 - val_loss: 9.0211 - val_mae: 1.5578\n",
      "Epoch 14/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 49.0405 - mae: 3.5682 - val_loss: 9.4253 - val_mae: 1.7585\n",
      "Epoch 15/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 51.3468 - mae: 3.5814 - val_loss: 4.3855 - val_mae: 0.9799\n",
      "Epoch 16/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 50.5451 - mae: 3.5225 - val_loss: 5.5110 - val_mae: 1.2601\n",
      "Epoch 17/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 47.6972 - mae: 3.4431 - val_loss: 5.5861 - val_mae: 1.4584\n",
      "Epoch 18/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 48.5017 - mae: 3.5269 - val_loss: 4.4862 - val_mae: 1.2403\n",
      "Epoch 19/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 46.8898 - mae: 3.3796 - val_loss: 11.1636 - val_mae: 1.8318\n",
      "Epoch 20/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 43.6602 - mae: 3.3407 - val_loss: 4.8762 - val_mae: 1.2061\n",
      "Epoch 21/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 45.9425 - mae: 3.3466 - val_loss: 4.0725 - val_mae: 1.1514\n",
      "Epoch 22/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 42.2212 - mae: 3.2124 - val_loss: 5.0783 - val_mae: 1.4261\n",
      "Epoch 23/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 45.9953 - mae: 3.3041 - val_loss: 2.9367 - val_mae: 1.0353\n",
      "Epoch 24/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 43.2997 - mae: 3.2472 - val_loss: 3.5768 - val_mae: 1.2695\n",
      "Epoch 25/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 43.5949 - mae: 3.2366 - val_loss: 3.2364 - val_mae: 1.0086\n",
      "Epoch 26/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 42.3355 - mae: 3.1984 - val_loss: 3.3206 - val_mae: 1.1698\n",
      "Epoch 27/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 42.9361 - mae: 3.2015 - val_loss: 9.2476 - val_mae: 1.7031\n",
      "Epoch 28/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 42.6078 - mae: 3.1699 - val_loss: 2.5357 - val_mae: 1.0258\n",
      "Epoch 29/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 39.9716 - mae: 3.1501 - val_loss: 5.7296 - val_mae: 1.4931\n",
      "Epoch 30/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 38.2156 - mae: 3.0695 - val_loss: 4.6996 - val_mae: 1.3553\n",
      "Epoch 31/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 40.5235 - mae: 3.1378 - val_loss: 2.3647 - val_mae: 1.0343\n",
      "Epoch 32/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 42.6607 - mae: 3.1149 - val_loss: 11.5345 - val_mae: 1.7693\n",
      "Epoch 33/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 42.7159 - mae: 3.1698 - val_loss: 2.7400 - val_mae: 1.0556\n",
      "Epoch 34/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 39.2393 - mae: 3.1260 - val_loss: 6.4676 - val_mae: 1.5787\n",
      "Epoch 35/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 36.9962 - mae: 3.0468 - val_loss: 6.0418 - val_mae: 1.4417\n",
      "Epoch 36/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 37.8481 - mae: 3.0861 - val_loss: 5.5154 - val_mae: 1.4289\n",
      "Epoch 37/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 39.7597 - mae: 3.1272 - val_loss: 3.1676 - val_mae: 1.1829\n",
      "Epoch 38/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 39.6322 - mae: 3.1515 - val_loss: 3.4488 - val_mae: 1.2523\n",
      "Epoch 39/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 39.3000 - mae: 3.1366 - val_loss: 4.8252 - val_mae: 1.3774\n",
      "Epoch 40/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 39.7975 - mae: 3.1487 - val_loss: 5.9072 - val_mae: 1.6966\n",
      "Epoch 41/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 39.1749 - mae: 3.1054 - val_loss: 4.8469 - val_mae: 1.5662\n",
      "Epoch 42/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 39.9964 - mae: 3.1640 - val_loss: 8.5111 - val_mae: 1.7991\n",
      "Epoch 43/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 36.5760 - mae: 3.1125 - val_loss: 2.9005 - val_mae: 1.1809\n",
      "Epoch 44/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 38.8153 - mae: 3.1679 - val_loss: 3.1404 - val_mae: 1.1733\n",
      "Epoch 45/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 37.1803 - mae: 3.1287 - val_loss: 2.8783 - val_mae: 1.1965\n",
      "Epoch 46/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 37.1479 - mae: 3.1581 - val_loss: 3.1247 - val_mae: 1.2656\n",
      "Epoch 47/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 39.2918 - mae: 3.1827 - val_loss: 4.9909 - val_mae: 1.2662\n",
      "Epoch 48/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 38.0670 - mae: 3.2076 - val_loss: 5.1166 - val_mae: 1.6400\n",
      "Epoch 49/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 38.2703 - mae: 3.1317 - val_loss: 3.2441 - val_mae: 1.3025\n",
      "Epoch 50/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 40.5699 - mae: 3.1712 - val_loss: 4.9564 - val_mae: 1.3808\n",
      "Epoch 51/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 41.4906 - mae: 3.1163 - val_loss: 6.3927 - val_mae: 1.6764\n",
      "Epoch 52/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 38.3270 - mae: 2.9939 - val_loss: 2.6657 - val_mae: 1.0449\n",
      "Epoch 53/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 36.1434 - mae: 2.8641 - val_loss: 5.6962 - val_mae: 1.4157\n",
      "Epoch 54/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 39.0160 - mae: 2.9345 - val_loss: 5.4908 - val_mae: 1.3397\n",
      "Epoch 55/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 35.9627 - mae: 2.8603 - val_loss: 5.9041 - val_mae: 1.3557\n",
      "Epoch 56/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 38.8129 - mae: 2.8928 - val_loss: 6.3873 - val_mae: 1.3799\n",
      "Epoch 57/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 36.9987 - mae: 2.8948 - val_loss: 2.2303 - val_mae: 0.8449\n",
      "Epoch 58/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 35.4464 - mae: 2.8256 - val_loss: 10.5682 - val_mae: 1.7833\n",
      "Epoch 59/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 37.6168 - mae: 2.8280 - val_loss: 4.6033 - val_mae: 1.1882\n",
      "Epoch 60/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 38.2683 - mae: 2.8379 - val_loss: 3.9340 - val_mae: 1.1861\n",
      "Epoch 61/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 36.1161 - mae: 2.7807 - val_loss: 2.6212 - val_mae: 1.0908\n",
      "Epoch 62/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 38.7377 - mae: 2.9250 - val_loss: 2.0503 - val_mae: 0.8569\n",
      "Epoch 63/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 36.1926 - mae: 2.7847 - val_loss: 3.9551 - val_mae: 1.2232\n",
      "Epoch 64/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 36.7340 - mae: 2.8683 - val_loss: 2.6344 - val_mae: 1.0210\n",
      "Epoch 65/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 38.3106 - mae: 2.8425 - val_loss: 13.1481 - val_mae: 1.6318\n",
      "Epoch 66/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 37.0434 - mae: 2.8242 - val_loss: 2.2905 - val_mae: 0.9654\n",
      "Epoch 67/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 37.2806 - mae: 2.8509 - val_loss: 1.9337 - val_mae: 0.7450\n",
      "Epoch 68/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 35.0437 - mae: 2.8068 - val_loss: 4.2775 - val_mae: 1.1623\n",
      "Epoch 69/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 37.3659 - mae: 2.8192 - val_loss: 6.8072 - val_mae: 1.4286\n",
      "Epoch 70/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 36.3727 - mae: 2.7827 - val_loss: 6.1766 - val_mae: 1.1619\n",
      "Epoch 71/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 37.9585 - mae: 2.8126 - val_loss: 4.9540 - val_mae: 1.1231\n",
      "Epoch 72/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 33.8721 - mae: 2.7378 - val_loss: 1.2849 - val_mae: 0.6803\n",
      "Epoch 73/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 35.9839 - mae: 2.7901 - val_loss: 2.0033 - val_mae: 0.8541\n",
      "Epoch 74/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 35.6813 - mae: 2.7640 - val_loss: 3.4042 - val_mae: 1.0209\n",
      "Epoch 75/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 35.4385 - mae: 2.7724 - val_loss: 2.8074 - val_mae: 0.8916\n",
      "Epoch 76/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 38.0808 - mae: 2.8388 - val_loss: 3.3643 - val_mae: 1.1759\n",
      "Epoch 77/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 33.6905 - mae: 2.7465 - val_loss: 2.5998 - val_mae: 0.8864\n",
      "Epoch 78/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 36.2320 - mae: 2.8216 - val_loss: 1.5778 - val_mae: 0.7106\n",
      "Epoch 79/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 35.3717 - mae: 2.7876 - val_loss: 7.4918 - val_mae: 1.5097\n",
      "Epoch 80/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 36.1273 - mae: 2.8018 - val_loss: 1.8883 - val_mae: 0.7380\n",
      "Epoch 81/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 33.2893 - mae: 2.7150 - val_loss: 1.6212 - val_mae: 0.8160\n",
      "Epoch 82/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 35.4694 - mae: 2.7413 - val_loss: 3.0122 - val_mae: 0.9813\n",
      "Epoch 83/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 34.1681 - mae: 2.7630 - val_loss: 3.2564 - val_mae: 0.9436\n",
      "Epoch 84/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 35.7034 - mae: 2.7658 - val_loss: 2.3242 - val_mae: 0.9152\n",
      "Epoch 85/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 33.6785 - mae: 2.7359 - val_loss: 1.1975 - val_mae: 0.7113\n",
      "Epoch 86/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 36.1149 - mae: 2.7612 - val_loss: 7.3836 - val_mae: 1.3241\n",
      "Epoch 87/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 33.4872 - mae: 2.7619 - val_loss: 2.8731 - val_mae: 1.0487\n",
      "Epoch 88/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 34.3071 - mae: 2.7710 - val_loss: 5.3384 - val_mae: 1.1626\n",
      "Epoch 89/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 35.0528 - mae: 2.7850 - val_loss: 2.1855 - val_mae: 1.0207\n",
      "Epoch 90/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 33.4327 - mae: 2.7370 - val_loss: 2.4353 - val_mae: 0.9687\n",
      "Epoch 91/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 33.8900 - mae: 2.7598 - val_loss: 6.6978 - val_mae: 1.4504\n",
      "Epoch 92/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 35.0582 - mae: 2.8221 - val_loss: 2.1068 - val_mae: 0.8111\n",
      "Epoch 93/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 34.1795 - mae: 2.8026 - val_loss: 2.1759 - val_mae: 0.7891\n",
      "Epoch 94/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 33.3862 - mae: 2.7285 - val_loss: 1.7722 - val_mae: 0.7337\n",
      "Epoch 95/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 34.5273 - mae: 2.7584 - val_loss: 3.0934 - val_mae: 1.1528\n",
      "Epoch 96/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 34.9288 - mae: 2.7777 - val_loss: 4.2455 - val_mae: 1.1510\n",
      "Epoch 97/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 33.7787 - mae: 2.7727 - val_loss: 2.7040 - val_mae: 0.8250\n",
      "Epoch 98/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 33.7224 - mae: 2.7711 - val_loss: 2.7793 - val_mae: 0.8454\n",
      "Epoch 99/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 31.9231 - mae: 2.7504 - val_loss: 3.5376 - val_mae: 1.2092\n",
      "Epoch 100/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 33.4451 - mae: 2.7532 - val_loss: 4.4881 - val_mae: 0.9971\n",
      "Epoch 101/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 35.1674 - mae: 2.7951 - val_loss: 5.1645 - val_mae: 1.3853\n",
      "Epoch 102/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 33.6284 - mae: 2.7583 - val_loss: 2.0519 - val_mae: 0.9185\n",
      "Epoch 103/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 35.3450 - mae: 2.8443 - val_loss: 2.4111 - val_mae: 0.8686\n",
      "Epoch 104/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 32.8462 - mae: 2.7433 - val_loss: 1.5436 - val_mae: 0.7668\n",
      "Epoch 105/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 31.5305 - mae: 2.7571 - val_loss: 6.8486 - val_mae: 1.1084\n",
      "Epoch 106/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 32.6285 - mae: 2.7599 - val_loss: 1.1358 - val_mae: 0.6180\n",
      "Epoch 107/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 33.7544 - mae: 2.8316 - val_loss: 2.9512 - val_mae: 0.9570\n",
      "Epoch 108/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 32.5818 - mae: 2.7718 - val_loss: 2.2069 - val_mae: 0.8610\n",
      "Epoch 109/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 31.7992 - mae: 2.7013 - val_loss: 3.2553 - val_mae: 1.0299\n",
      "Epoch 110/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 31.2803 - mae: 2.7151 - val_loss: 3.2763 - val_mae: 1.2437\n",
      "Epoch 111/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 31.4194 - mae: 2.7151 - val_loss: 2.4813 - val_mae: 1.0778\n",
      "Epoch 112/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 32.6349 - mae: 2.7550 - val_loss: 1.9032 - val_mae: 0.8679\n",
      "Epoch 113/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 32.4497 - mae: 2.7708 - val_loss: 2.1628 - val_mae: 0.9284\n",
      "Epoch 114/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 33.7211 - mae: 2.7672 - val_loss: 4.9992 - val_mae: 1.1469\n",
      "Epoch 115/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 34.7026 - mae: 2.8083 - val_loss: 2.1458 - val_mae: 0.7527\n",
      "Epoch 116/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 35.4720 - mae: 2.7941 - val_loss: 2.0111 - val_mae: 0.8138\n",
      "Epoch 117/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 31.4484 - mae: 2.7372 - val_loss: 2.4473 - val_mae: 1.0254\n",
      "Epoch 118/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 33.4639 - mae: 2.7697 - val_loss: 2.9737 - val_mae: 1.0289\n",
      "Epoch 119/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 29.9689 - mae: 2.7089 - val_loss: 2.2528 - val_mae: 0.9877\n",
      "Epoch 120/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 34.4110 - mae: 2.8028 - val_loss: 2.8522 - val_mae: 0.8833\n",
      "Epoch 121/200\n",
      "277/277 [==============================] - 1s 5ms/step - loss: 32.4104 - mae: 2.7964 - val_loss: 3.7538 - val_mae: 1.0330\n",
      "Epoch 122/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 33.4919 - mae: 2.8160 - val_loss: 1.5214 - val_mae: 0.7061\n",
      "Epoch 123/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 31.6354 - mae: 2.7301 - val_loss: 3.7295 - val_mae: 1.1485\n",
      "Epoch 124/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 31.6549 - mae: 2.7945 - val_loss: 1.7470 - val_mae: 0.6240\n",
      "Epoch 125/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 33.0338 - mae: 2.7762 - val_loss: 1.7300 - val_mae: 0.7114\n",
      "Epoch 126/200\n",
      "277/277 [==============================] - 1s 4ms/step - loss: 32.8596 - mae: 2.7864 - val_loss: 10.9884 - val_mae: 1.8447\n",
      "Epoch 127/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 29.2333 - mae: 2.7161 - val_loss: 4.3666 - val_mae: 1.2785\n",
      "Epoch 128/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 31.3275 - mae: 2.7884 - val_loss: 2.8670 - val_mae: 1.0139\n",
      "Epoch 129/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 33.3411 - mae: 2.8114 - val_loss: 1.7903 - val_mae: 0.7936\n",
      "Epoch 130/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 31.1801 - mae: 2.7772 - val_loss: 2.5188 - val_mae: 0.9899\n",
      "Epoch 131/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 33.8953 - mae: 2.8354 - val_loss: 2.7278 - val_mae: 0.9801\n",
      "Epoch 132/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 30.0277 - mae: 2.7392 - val_loss: 2.6959 - val_mae: 1.1512\n",
      "Epoch 133/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 32.4352 - mae: 2.8184 - val_loss: 1.5594 - val_mae: 0.7069\n",
      "Epoch 134/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 31.0844 - mae: 2.7710 - val_loss: 4.7462 - val_mae: 1.1459\n",
      "Epoch 135/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 32.5971 - mae: 2.8253 - val_loss: 6.1489 - val_mae: 1.4091\n",
      "Epoch 136/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 30.7896 - mae: 2.7703 - val_loss: 2.1231 - val_mae: 0.8452\n",
      "Epoch 137/200\n",
      "277/277 [==============================] - 1s 4ms/step - loss: 30.0771 - mae: 2.7631 - val_loss: 1.1664 - val_mae: 0.7315\n",
      "Epoch 138/200\n",
      "277/277 [==============================] - 1s 4ms/step - loss: 31.2106 - mae: 2.8173 - val_loss: 2.6382 - val_mae: 1.1284\n",
      "Epoch 139/200\n",
      "277/277 [==============================] - 1s 5ms/step - loss: 30.0330 - mae: 2.7615 - val_loss: 3.6130 - val_mae: 0.9621\n",
      "Epoch 140/200\n",
      "277/277 [==============================] - 1s 5ms/step - loss: 30.8678 - mae: 2.7666 - val_loss: 3.2319 - val_mae: 1.1220\n",
      "Epoch 141/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 29.7047 - mae: 2.7768 - val_loss: 5.8021 - val_mae: 1.4487\n",
      "Epoch 142/200\n",
      "277/277 [==============================] - 1s 4ms/step - loss: 31.5390 - mae: 2.8282 - val_loss: 3.0221 - val_mae: 0.7673\n",
      "Epoch 143/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 28.8727 - mae: 2.7530 - val_loss: 4.7005 - val_mae: 1.4539\n",
      "Epoch 144/200\n",
      "277/277 [==============================] - 2s 8ms/step - loss: 30.0431 - mae: 2.7550 - val_loss: 2.8932 - val_mae: 0.9997\n",
      "Epoch 145/200\n",
      "277/277 [==============================] - 2s 8ms/step - loss: 31.1844 - mae: 2.8201 - val_loss: 3.3595 - val_mae: 0.9482\n",
      "Epoch 146/200\n",
      "277/277 [==============================] - 2s 9ms/step - loss: 33.9594 - mae: 2.8798 - val_loss: 3.1844 - val_mae: 1.1912\n",
      "Epoch 147/200\n",
      "277/277 [==============================] - 2s 8ms/step - loss: 30.1670 - mae: 2.7680 - val_loss: 1.6609 - val_mae: 0.6901\n",
      "Epoch 148/200\n",
      "277/277 [==============================] - 2s 9ms/step - loss: 30.1322 - mae: 2.8007 - val_loss: 3.3434 - val_mae: 1.0845\n",
      "Epoch 149/200\n",
      "277/277 [==============================] - 2s 8ms/step - loss: 31.1111 - mae: 2.8343 - val_loss: 1.6511 - val_mae: 0.7991\n",
      "Epoch 150/200\n",
      "277/277 [==============================] - 2s 9ms/step - loss: 32.2841 - mae: 2.8188 - val_loss: 2.7171 - val_mae: 0.7966\n",
      "Epoch 151/200\n",
      "277/277 [==============================] - 2s 9ms/step - loss: 30.2061 - mae: 2.7777 - val_loss: 2.1518 - val_mae: 0.7987\n",
      "Epoch 152/200\n",
      "277/277 [==============================] - 2s 8ms/step - loss: 29.8625 - mae: 2.8061 - val_loss: 3.6995 - val_mae: 1.2312\n",
      "Epoch 153/200\n",
      "277/277 [==============================] - 2s 8ms/step - loss: 32.4781 - mae: 2.8646 - val_loss: 1.5523 - val_mae: 0.6622\n",
      "Epoch 154/200\n",
      "277/277 [==============================] - 2s 8ms/step - loss: 30.2768 - mae: 2.8079 - val_loss: 2.6213 - val_mae: 1.0910\n",
      "Epoch 155/200\n",
      "277/277 [==============================] - 3s 12ms/step - loss: 32.9372 - mae: 2.8432 - val_loss: 1.2448 - val_mae: 0.6695\n",
      "Epoch 156/200\n",
      "277/277 [==============================] - 2s 6ms/step - loss: 31.0659 - mae: 2.8009 - val_loss: 1.9729 - val_mae: 0.7991\n",
      "Epoch 157/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 30.5631 - mae: 2.8276 - val_loss: 2.6493 - val_mae: 0.8992\n",
      "Epoch 158/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 31.2055 - mae: 2.8352 - val_loss: 5.0054 - val_mae: 1.4649\n",
      "Epoch 159/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 32.5347 - mae: 2.8664 - val_loss: 1.0432 - val_mae: 0.6807\n",
      "Epoch 160/200\n",
      "277/277 [==============================] - 1s 4ms/step - loss: 31.9049 - mae: 2.8775 - val_loss: 2.1615 - val_mae: 0.9511\n",
      "Epoch 161/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 30.1548 - mae: 2.8504 - val_loss: 1.0648 - val_mae: 0.6374\n",
      "Epoch 162/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 31.3232 - mae: 2.8770 - val_loss: 1.7842 - val_mae: 0.9643\n",
      "Epoch 163/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 31.1917 - mae: 2.8751 - val_loss: 2.2916 - val_mae: 0.8156\n",
      "Epoch 164/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 32.0684 - mae: 2.8787 - val_loss: 1.6252 - val_mae: 0.8858\n",
      "Epoch 165/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 33.5282 - mae: 2.8874 - val_loss: 2.4362 - val_mae: 1.0088\n",
      "Epoch 166/200\n",
      "277/277 [==============================] - 2s 8ms/step - loss: 29.2592 - mae: 2.8477 - val_loss: 5.4046 - val_mae: 1.1549\n",
      "Epoch 167/200\n",
      "277/277 [==============================] - 2s 9ms/step - loss: 31.9910 - mae: 2.9178 - val_loss: 1.8193 - val_mae: 0.7983\n",
      "Epoch 168/200\n",
      "277/277 [==============================] - 2s 8ms/step - loss: 30.4939 - mae: 2.8352 - val_loss: 1.3533 - val_mae: 0.9027\n",
      "Epoch 169/200\n",
      "277/277 [==============================] - 3s 10ms/step - loss: 31.5644 - mae: 2.8724 - val_loss: 0.9814 - val_mae: 0.7141\n",
      "Epoch 170/200\n",
      "277/277 [==============================] - 2s 8ms/step - loss: 32.0186 - mae: 2.8706 - val_loss: 1.3908 - val_mae: 0.8013\n",
      "Epoch 171/200\n",
      "277/277 [==============================] - 2s 8ms/step - loss: 31.6218 - mae: 2.8752 - val_loss: 2.2744 - val_mae: 0.7897\n",
      "Epoch 172/200\n",
      "277/277 [==============================] - 2s 8ms/step - loss: 29.5855 - mae: 2.8341 - val_loss: 1.3626 - val_mae: 0.6025\n",
      "Epoch 173/200\n",
      "277/277 [==============================] - 2s 8ms/step - loss: 31.3520 - mae: 2.8841 - val_loss: 4.6808 - val_mae: 1.0402\n",
      "Epoch 174/200\n",
      "277/277 [==============================] - 2s 8ms/step - loss: 31.6606 - mae: 2.8730 - val_loss: 1.8192 - val_mae: 0.7851\n",
      "Epoch 175/200\n",
      "277/277 [==============================] - 2s 8ms/step - loss: 31.2026 - mae: 2.8807 - val_loss: 7.1884 - val_mae: 1.6917\n",
      "Epoch 176/200\n",
      "277/277 [==============================] - 3s 9ms/step - loss: 30.7223 - mae: 2.8638 - val_loss: 1.2196 - val_mae: 0.5755\n",
      "Epoch 177/200\n",
      "277/277 [==============================] - 2s 8ms/step - loss: 31.8527 - mae: 2.8897 - val_loss: 1.0673 - val_mae: 0.5928\n",
      "Epoch 178/200\n",
      "277/277 [==============================] - 3s 9ms/step - loss: 32.5812 - mae: 2.9228 - val_loss: 1.8539 - val_mae: 0.8416\n",
      "Epoch 179/200\n",
      "277/277 [==============================] - 1s 5ms/step - loss: 30.1158 - mae: 2.8691 - val_loss: 1.7960 - val_mae: 0.7269\n",
      "Epoch 180/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 31.7734 - mae: 2.8773 - val_loss: 1.9036 - val_mae: 0.8559\n",
      "Epoch 181/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 29.9225 - mae: 2.8668 - val_loss: 1.2448 - val_mae: 0.6372\n",
      "Epoch 182/200\n",
      "277/277 [==============================] - 1s 4ms/step - loss: 28.5702 - mae: 2.8461 - val_loss: 3.1803 - val_mae: 1.1887\n",
      "Epoch 183/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 29.7392 - mae: 2.8242 - val_loss: 0.9158 - val_mae: 0.6016\n",
      "Epoch 184/200\n",
      "277/277 [==============================] - 1s 4ms/step - loss: 32.4501 - mae: 2.9354 - val_loss: 2.9191 - val_mae: 0.9522\n",
      "Epoch 185/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 31.4880 - mae: 2.8925 - val_loss: 1.8382 - val_mae: 1.0140\n",
      "Epoch 186/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 30.2110 - mae: 2.8500 - val_loss: 2.7542 - val_mae: 0.9097\n",
      "Epoch 187/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 31.1670 - mae: 2.8947 - val_loss: 2.5137 - val_mae: 1.0813\n",
      "Epoch 188/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 31.4122 - mae: 2.8931 - val_loss: 2.1068 - val_mae: 1.0589\n",
      "Epoch 189/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 29.0962 - mae: 2.8637 - val_loss: 1.7050 - val_mae: 0.9325\n",
      "Epoch 190/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 29.4963 - mae: 2.8677 - val_loss: 2.8161 - val_mae: 1.1186\n",
      "Epoch 191/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 31.4671 - mae: 2.9003 - val_loss: 1.2606 - val_mae: 0.7076\n",
      "Epoch 192/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 30.2513 - mae: 2.8713 - val_loss: 3.3049 - val_mae: 0.9905\n",
      "Epoch 193/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 31.1917 - mae: 2.9171 - val_loss: 2.7058 - val_mae: 1.0617\n",
      "Epoch 194/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 32.6727 - mae: 2.8939 - val_loss: 2.0097 - val_mae: 0.8141\n",
      "Epoch 195/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 30.5399 - mae: 2.8941 - val_loss: 2.3992 - val_mae: 1.0432\n",
      "Epoch 196/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 30.3106 - mae: 2.8830 - val_loss: 3.1013 - val_mae: 0.8868\n",
      "Epoch 197/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 30.6451 - mae: 2.9119 - val_loss: 3.2245 - val_mae: 0.8934\n",
      "Epoch 198/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 30.8146 - mae: 2.9023 - val_loss: 1.0258 - val_mae: 0.6114\n",
      "Epoch 199/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 29.2945 - mae: 2.8578 - val_loss: 1.6761 - val_mae: 0.7199\n",
      "Epoch 200/200\n",
      "277/277 [==============================] - 1s 3ms/step - loss: 30.2351 - mae: 2.9247 - val_loss: 2.1066 - val_mae: 0.8279\n",
      "1/1 [==============================] - 0s 228ms/step\n",
      "Predicted Price: [[42.190914]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming df is your training DataFrame\n",
    "categorical_cols = ['Purchase Type', 'Payment Method', 'Railcard', 'Ticket Class', 'Ticket Type', \n",
    "                    'Departure Station', 'Arrival Destination', 'Journey Status', \n",
    "                    'Reason for Delay', 'Refund Request']\n",
    "\n",
    "# Label encode categorical columns\n",
    "missing_value_placeholder = 'Missing'\n",
    "\n",
    "# Function to handle missing values in categorical columns\n",
    "def handle_missing_values(df, categorical_cols, placeholder='Missing'):\n",
    "    for col in categorical_cols:\n",
    "        # Replace NaN with the placeholder value\n",
    "        df[col] = df[col].fillna(placeholder)\n",
    "    return df\n",
    "\n",
    "# Function to safely fit and transform categorical columns\n",
    "def safe_label_encoder(df, categorical_cols):\n",
    "    label_encoders = {}\n",
    "    for col in categorical_cols:\n",
    "        label_encoders[col] = LabelEncoder()\n",
    "        df[col] = df[col].fillna(missing_value_placeholder)  # Handle missing values\n",
    "        df[col] = label_encoders[col].fit_transform(df[col].astype(str))  # Encode\n",
    "    return label_encoders, df\n",
    "\n",
    "# Train the model on the training data\n",
    "label_encoders, df = safe_label_encoder(df, categorical_cols)\n",
    "\n",
    "# Prepare the features (X) and target (y)\n",
    "X = df[categorical_cols]\n",
    "y = df['Price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Define the combined model with embedding layers and regression layers\n",
    "def create_combined_model(input_shape):\n",
    "    inputs = []\n",
    "    embeddings = []\n",
    "    \n",
    "    # Create an embedding layer for each categorical column\n",
    "    for i, col in enumerate(X_train.columns):\n",
    "        input_layer = layers.Input(shape=(1,), dtype=tf.int32, name=f\"input_{col}\")\n",
    "        embed_dim = int(np.ceil(len(df[col].unique()) ** 0.25))  # Embedding dimension\n",
    "        embed_layer = layers.Embedding(input_dim=len(df[col].unique()), output_dim=embed_dim)(input_layer)\n",
    "        embeddings.append(embed_layer)\n",
    "        inputs.append(input_layer)\n",
    "    \n",
    "    # Concatenate all embedding layers\n",
    "    x = layers.Concatenate()(embeddings)\n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    # Add dense layers for regression\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dense(32, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)  # Dropout for regularization\n",
    "    output = layers.Dense(1)(x)  # Regression output (price prediction)\n",
    "    \n",
    "    # Create and compile the model\n",
    "    model = models.Model(inputs=inputs, outputs=output)\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Instantiate and summarize the model\n",
    "model = create_combined_model(X_train.shape)\n",
    "model.summary()\n",
    "\n",
    "# Prepare the input data for the model (convert categorical columns to list of inputs)\n",
    "train_inputs = [X_train[col].values for col in X_train.columns]\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_inputs, y_train, epochs=200, batch_size=64, validation_split=0.3)\n",
    "\n",
    "# Now the model is trained and ready for inference on new data\n",
    "\n",
    "\n",
    "# Assuming df_new is your new (unseen) data for inference\n",
    "df_new = pd.DataFrame({\n",
    "    'Purchase Type': ['Online'],\n",
    "    'Payment Method': ['Credit Card'],\n",
    "    'Railcard': ['Adult'],\n",
    "    'Ticket Class': ['Standard'],\n",
    "    'Ticket Type': ['Advance'],\n",
    "    'Departure Station': ['London Kings Cross'],\n",
    "    'Arrival Destination': ['Liverpool Lime Street'],\n",
    "    'Journey Status': ['Delayed'],\n",
    "    'Reason for Delay': ['Signal Failure'],\n",
    "    'Refund Request': ['No']\n",
    "})\n",
    "\n",
    "# Step 1: Handle missing values in new data\n",
    "df_new = handle_missing_values(df_new, categorical_cols, placeholder=missing_value_placeholder)\n",
    "\n",
    "# Step 2: Apply the label encoding for the new data using the same label encoders\n",
    "for col in categorical_cols:\n",
    "    if df_new[col].iloc[0] not in label_encoders[col].classes_:\n",
    "        # If the value is not in the classes, assign a default encoding (e.g., 0 or 'Missing')\n",
    "        df_new[col] = label_encoders[col].transform([missing_value_placeholder])[0]\n",
    "    else:\n",
    "        df_new[col] = label_encoders[col].transform(df_new[col].astype(str))\n",
    "\n",
    "# Step 3: Prepare the input data for the model\n",
    "input_data = [df_new[col].values for col in df_new.columns]\n",
    "\n",
    "# Step 4: Make a prediction using the trained model\n",
    "prediction = model.predict(input_data)\n",
    "\n",
    "# Step 5: Output the prediction (predicted price)\n",
    "print(\"Predicted Price:\", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198/198 [==============================] - 0s 2ms/step\n",
      "Mean Absolute Error (MAE): 0.7914\n",
      "Mean Squared Error (MSE): 1.8518\n",
      "Root Mean Squared Error (RMSE): 1.3608\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Prepare the input data for the model (convert categorical columns to list of inputs)\n",
    "test_inputs = [X_test[col].values for col in X_test.columns]\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(test_inputs).flatten()\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5  # Square root of MSE\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "Predicted Price: [[70.13487]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Assuming df_new is your new (unseen) data for inference\n",
    "df_new = pd.DataFrame({\n",
    "    'Purchase Type': ['Online'],\n",
    "    'Payment Method': ['Debit Card'],\n",
    "    'Railcard': ['Adult'],\n",
    "    'Ticket Class': ['First Class'],\n",
    "    'Ticket Type': ['Advance'],\n",
    "    'Departure Station': ['London Kings Cross'],\n",
    "    'Arrival Destination': ['Manchester Piccadilly'],\n",
    "    'Journey Status': ['On Time'],\n",
    "    'Reason for Delay': ['Missing'],\n",
    "    'Refund Request': ['Yes']\n",
    "})\n",
    "\n",
    "# Step 1: Handle missing values in new data\n",
    "df_new = handle_missing_values(df_new, categorical_cols, placeholder=missing_value_placeholder)\n",
    "\n",
    "# Step 2: Apply the label encoding for the new data using the same label encoders\n",
    "for col in categorical_cols:\n",
    "    if df_new[col].iloc[0] not in label_encoders[col].classes_:\n",
    "        # If the value is not in the classes, assign a default encoding (e.g., 0 or 'Missing')\n",
    "        df_new[col] = label_encoders[col].transform([missing_value_placeholder])[0]\n",
    "    else:\n",
    "        df_new[col] = label_encoders[col].transform(df_new[col].astype(str))\n",
    "\n",
    "# Step 3: Prepare the input data for the model\n",
    "input_data = [df_new[col].values for col in df_new.columns]\n",
    "\n",
    "# Step 4: Make a prediction using the trained model\n",
    "prediction = model.predict(input_data)\n",
    "\n",
    "# Step 5: Output the prediction (predicted price)\n",
    "print(\"Predicted Price:\", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('trained_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoders.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the label encoders\n",
    "joblib.dump(label_encoders, 'label_encoders.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
